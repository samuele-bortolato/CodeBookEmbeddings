{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam\\miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, GlueDataTrainingArguments, AutoTokenizer\n",
    "import torchmetrics\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apx import ApproxEmbed, ApxSVD, train_apx\n",
    "from glue_score import GLUE_TASKS, make_model, Glue, get_dataloaders, validate, get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.utils.logging.set_verbosity_error()\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "\n",
    "epochs=3\n",
    "batch_size=32\n",
    "\n",
    "lr=5e-5\n",
    "levels=8\n",
    "channels=8\n",
    "bits=8\n",
    "neurons=64\n",
    "nn_levels=2\n",
    "apx_epochs=5000\n",
    "apx_batch_size=2**14\n",
    "checkpoint_every=100\n",
    "\n",
    "save_path = 'results/compression_finetuned/'\n",
    "\n",
    "norms = [1,1.25,1.5,1.75,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Sam/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (C:/Users/Sam/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Epoch: 1: 100%|██████████| 268/268 [00:07<00:00, 34.84it/s, loss: 0.204]\n",
      "Epoch: 2: 100%|██████████| 268/268 [00:07<00:00, 36.47it/s, loss: 0.203]\n",
      "Epoch: 3: 100%|██████████| 268/268 [00:07<00:00, 36.44it/s, loss: 0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original [tensor(0)]\n",
      "1.25 [tensor(0)]\n",
      "SVD [tensor(0)]\n"
     ]
    }
   ],
   "source": [
    "RESULTS={}\n",
    "for task in list(GLUE_TASKS.keys()):\n",
    "    \n",
    "    print(task)\n",
    "    args=GLUE_TASKS[task]\n",
    "    model=make_model('prajjwal1/bert-tiny',args)\n",
    "    \n",
    "    train_dataloader, val_dataloader = get_dataloaders(args, task, batch_size)\n",
    "    metrics = get_metrics(args)\n",
    "\n",
    "    Glue(model, tokenizer, task, args, epochs=epochs, steps_validate=0.2, train_dataloader=train_dataloader, val_dataloader=val_dataloader);\n",
    "\n",
    "    embeddings = model.bert.embeddings.word_embeddings.weight.to(device)\n",
    "\n",
    "    results={}\n",
    "\n",
    "    val_metrics = validate(model, tokenizer, val_dataloader, metrics, args)\n",
    "    results['Original']=[m.item() for m in val_metrics]\n",
    "    print('Original', val_metrics)\n",
    "\n",
    "    for norm in norms:\n",
    "\n",
    "        # clone the model to not modify the original\n",
    "        apx_model = make_model('prajjwal1/bert-tiny',args)\n",
    "        apx_model.load_state_dict(model.state_dict())\n",
    "\n",
    "        apx = ApproxEmbed(levels = levels, \n",
    "                feature_dim = channels,\n",
    "                num_words = embeddings.shape[0],\n",
    "                output_dims = embeddings.shape[1],\n",
    "                feature_std = 0.1,\n",
    "                feature_bias = 0.0,\n",
    "                codebook_bitwidth=bits,\n",
    "                neurons = neurons,\n",
    "                nn_levels=nn_levels).to('cuda')\n",
    "\n",
    "        train_apx(apx, embeddings, apx_epochs, apx_batch_size, checkpoint_every, save_path);\n",
    "        apx.fix_indices()\n",
    "        apx_model.bert.embeddings.word_embeddings = apx\n",
    "\n",
    "        val_metrics = validate(apx_model, tokenizer, val_dataloader, metrics, args)\n",
    "        results[\"Norm \"+str(norm)]=[m.item() for m in val_metrics]\n",
    "        print(norm, val_metrics)\n",
    "\n",
    "    # clone the model to not modify the original\n",
    "    apx_model = make_model('prajjwal1/bert-tiny',args)\n",
    "    apx_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    apxSVD = ApxSVD(apx_model.bert.embeddings.word_embeddings.weight, 5)\n",
    "    apx_model.bert.embeddings.word_embeddings = apxSVD.to('cuda')\n",
    "\n",
    "    val_metrics = validate(apx_model, tokenizer, val_dataloader, metrics, args)\n",
    "    results['SVD']=[m.item() for m in val_metrics]\n",
    "    print('SVD', val_metrics)\n",
    "\n",
    "    RESULTS[task]=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cola': {'Original': [0], 'Norm1.25': [0], 'SVD': [0]}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='results/'\n",
    "import os\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "torch.save(RESULTS, save_path+'glue_results_no_retrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cola</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Norm1.25</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cola\n",
       "Norm1.25  0.0\n",
       "Original  0.0\n",
       "SVD       0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "run_dict=torch.load('results/glue_results_no_retrain.pth')\n",
    "\n",
    "for k_runs, runs in run_dict.items():\n",
    "    for k_run, run in runs.items():\n",
    "        run_dict[k_runs][k_run]=f\"{run[0]*100:,.1f}\" if len(run)==1 else f\"{run[0]*100:,.1f}/{run[1]*100:,.1f}\"\n",
    "df=pd.DataFrame(run_dict)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "506daaeaa79bc5d30715519e2bba71fd2fb898b1f12d903345e89400e3b4f753"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
